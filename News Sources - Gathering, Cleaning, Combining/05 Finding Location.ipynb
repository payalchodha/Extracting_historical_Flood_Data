{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Location from textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the csv files\n",
    "Read in the combined csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data from reliefweb AFTER 2006\n",
    "# Notice: after the csv name there is an additional argument \n",
    "    \n",
    "df= pd.read_csv(\"./combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>https://www.tribuneindia.com/news/punjab/flood...</td>\n",
       "      <td>flood-hit farmers to get 9k-quintal wheat seed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>https://www.tribuneindia.com/news/punjab/debt-...</td>\n",
       "      <td>debt relief likely for flood-hit farmers. ruch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>https://www.tribuneindia.com/news/punjab/no-wh...</td>\n",
       "      <td>no wheat seed disbursal, farmers livid. aparna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>https://www.tribuneindia.com/news/punjab/farme...</td>\n",
       "      <td>farmers in flood-affected areas to get free wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>https://www.tribuneindia.com/news/punjab/busin...</td>\n",
       "      <td>business sinks in mandis of flood-hit lohian. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                             source  \\\n",
       "0  2019-10-21  https://www.tribuneindia.com/news/punjab/flood...   \n",
       "1  2019-10-16  https://www.tribuneindia.com/news/punjab/debt-...   \n",
       "2  2019-10-14  https://www.tribuneindia.com/news/punjab/no-wh...   \n",
       "3  2019-10-14  https://www.tribuneindia.com/news/punjab/farme...   \n",
       "4  2019-10-11  https://www.tribuneindia.com/news/punjab/busin...   \n",
       "\n",
       "                                                text  \n",
       "0  flood-hit farmers to get 9k-quintal wheat seed...  \n",
       "1  debt relief likely for flood-hit farmers. ruch...  \n",
       "2  no wheat seed disbursal, farmers livid. aparna...  \n",
       "3  farmers in flood-affected areas to get free wh...  \n",
       "4  business sinks in mandis of flood-hit lohian. ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Districts\n",
    "location= pd.read_csv(\"./latlongpunjab.csv\")\n",
    "location = location['Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "location = location.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding some replacements based on more commonly used place names\n",
    "# fatehgarh sahib = fatehgarh\n",
    "# sbs nagar = nawanshahr, sbs\n",
    "# sas nagar = mohali, nagar\n",
    "# sas nagar = ajitgarh, nagar \n",
    "# sri muktsar sahib = muktsar\n",
    "added_names = pd.Series(['fatehgarh','nawanshahr','mohali','ajitgarh','muktsar','nagar','sbs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = location.append(added_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Location in the Text & URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to pass in the list\n",
    "def location_fcn(lst, df):\n",
    "    for i in lst:\n",
    "        df[i] = df['source'].str.count(i) + df['text'].str.count(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_fcn(location, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                 2019-10-212019-10-162019-10-142019-10-142019-1...\n",
       "source               https://www.tribuneindia.com/news/punjab/flood...\n",
       "text                 flood-hit farmers to get 9k-quintal wheat seed...\n",
       "amritsar                                                           223\n",
       "barnala                                                             40\n",
       "bathinda                                                           199\n",
       "faridkot                                                            66\n",
       "fatehgarh sahib                                                     82\n",
       "fazilka                                                            185\n",
       "ferozepur                                                          322\n",
       "gurdaspur                                                          206\n",
       "hoshiarpur                                                          74\n",
       "jalandhar                                                          564\n",
       "kapurthala                                                         227\n",
       "ludhiana                                                           295\n",
       "mansa                                                              115\n",
       "moga                                                               268\n",
       "pathankot                                                           97\n",
       "patiala                                                            358\n",
       "roopnagar                                                           11\n",
       "sangrur                                                            215\n",
       "sas nagar                                                           14\n",
       "sbs nagar                                                            3\n",
       "sri muktsar sahib                                                    0\n",
       "tarn taran                                                          76\n",
       "fatehgarh                                                          105\n",
       "nawanshahr                                                          65\n",
       "mohali                                                              85\n",
       "ajitgarh                                                             1\n",
       "muktsar                                                            350\n",
       "nagar                                                              365\n",
       "sbs                                                                  6\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining columns for the extra names back to the original name\n",
    "# fatehgarh sahib = fatehgarh\n",
    "# sbs nagar = nawanshahr, sbs\n",
    "# sas nagar = mohali, nagar\n",
    "# sas nagar = ajitgarh, nagar \n",
    "# sri muktsar sahib = muktsar\n",
    "df['fatehgarh sahib'] = df['fatehgarh sahib'] + df['fatehgarh']\n",
    "df['sbs nagar'] = df['sbs nagar'] + df['nawanshahr']+ df['sbs']\n",
    "df['sas nagar'] = df['sas nagar'] + df['mohali']+ df['nagar']+ df['ajitgarh']\n",
    "df['sri muktsar sahib'] = df['sri muktsar sahib'] + df['muktsar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['muktsar','mohali','nagar','ajitgarh','nawanshahr','sbs','fatehgarh'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                 2019-10-212019-10-162019-10-142019-10-142019-1...\n",
       "source               https://www.tribuneindia.com/news/punjab/flood...\n",
       "text                 flood-hit farmers to get 9k-quintal wheat seed...\n",
       "amritsar                                                           223\n",
       "barnala                                                             40\n",
       "bathinda                                                           199\n",
       "faridkot                                                            66\n",
       "fatehgarh sahib                                                    187\n",
       "fazilka                                                            185\n",
       "ferozepur                                                          322\n",
       "gurdaspur                                                          206\n",
       "hoshiarpur                                                          74\n",
       "jalandhar                                                          564\n",
       "kapurthala                                                         227\n",
       "ludhiana                                                           295\n",
       "mansa                                                              115\n",
       "moga                                                               268\n",
       "pathankot                                                           97\n",
       "patiala                                                            358\n",
       "roopnagar                                                           11\n",
       "sangrur                                                            215\n",
       "sas nagar                                                          465\n",
       "sbs nagar                                                           74\n",
       "sri muktsar sahib                                                  350\n",
       "tarn taran                                                          76\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding People, Crops, Homes, Money in the Text & URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding People Affected\n",
    "def people_fcn(lst, df):\n",
    "    sum_people = 0\n",
    "    for i in lst:\n",
    "        sum_people += df['source'].str.count(i) + df['text'].str.count(i)\n",
    "    df['people'] = sum_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "peeps = ['death', 'die', 'dead', 'people','resident','residents',\n",
    "                 'kill', 'evacuat', 'mortality','villager','villagers',\n",
    "                 'victim', 'suffer', 'rescue', 'toll', 'displace','displaced',\n",
    "                 'missing', 'drown', 'wound', 'survive','persons','family','families',\n",
    "                 'suffer', 'displace', 'strand', 'displace','person']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_fcn(peeps, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     365\n",
       "1     270\n",
       "2     165\n",
       "3     104\n",
       "4     101\n",
       "5      82\n",
       "6      49\n",
       "7      48\n",
       "8      43\n",
       "10     38\n",
       "9      28\n",
       "12     24\n",
       "11     23\n",
       "17     15\n",
       "19     13\n",
       "15     12\n",
       "14     11\n",
       "13      9\n",
       "18      8\n",
       "24      7\n",
       "23      7\n",
       "16      7\n",
       "22      6\n",
       "21      6\n",
       "33      5\n",
       "31      3\n",
       "28      3\n",
       "20      2\n",
       "25      2\n",
       "29      2\n",
       "30      2\n",
       "34      2\n",
       "49      1\n",
       "26      1\n",
       "27      1\n",
       "32      1\n",
       "37      1\n",
       "38      1\n",
       "43      1\n",
       "46      1\n",
       "47      1\n",
       "51      1\n",
       "Name: people, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['people'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Crops / Livestock Affected\n",
    "crop_livestock = ['damag', 'loss', 'lost','kill','farm','field','agriculture','stable','horse','horses',\n",
    "                 'destroy','crop', 'livestock', 'cattle','farmer','agricultural','land','lands','fields',\n",
    "                  'farmers','acre','acres','grain','basmati','paddy',\n",
    "                 'cow','sheep','pig','cows','pigs','corn','wheat','seed','soy','rice', 'crops']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Crops / Livestock Affected\n",
    "def crops_fcn(lst, df):\n",
    "    sum_crops = 0\n",
    "    for i in lst:\n",
    "        sum_crops += df['source'].str.count(i) + df['text'].str.count(i)\n",
    "    df['crops'] = sum_crops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops_fcn(crop_livestock, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      322\n",
       "2      163\n",
       "1      134\n",
       "3      122\n",
       "4      110\n",
       "      ... \n",
       "49       1\n",
       "48       1\n",
       "41       1\n",
       "39       1\n",
       "127      1\n",
       "Name: crops, Length: 70, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['crops'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Houses Affected\n",
    "house = ['damag', 'loss', 'lost', 'evacuat','houses','submerged','rooftop','rooftops','submerge',\n",
    "                 'affect', 'relief', 'relieve', 'destroy', 'dwelling','structural','village','villages',\n",
    "                 'house', 'roof', 'home', 'window','damage', 'structure', 'barn','hut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Homes Affected\n",
    "def home_fcn(lst, df):\n",
    "    sum_homes = 0\n",
    "    for i in lst:\n",
    "        sum_homes += df['source'].str.count(i) + df['text'].str.count(i)\n",
    "    df['homes'] = sum_homes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_fcn(house, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     384\n",
       "2     171\n",
       "3      98\n",
       "4      78\n",
       "5      65\n",
       "     ... \n",
       "51      1\n",
       "50      1\n",
       "89      1\n",
       "48      1\n",
       "91      1\n",
       "Name: homes, Length: 62, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['homes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the Money\n",
    "money = ['cost','money','dollar','rupee','economic','economy','value','pounds','euro','compensation', 'rupees','dollars','euros']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the Money\n",
    "def money_fcn(lst, df):\n",
    "    sum_money = 0\n",
    "    for i in lst:\n",
    "        sum_money += df['source'].str.count(i) + df['text'].str.count(i)\n",
    "    df['money'] = sum_money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "money_fcn(money, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1177\n",
       "1      140\n",
       "2       76\n",
       "3       35\n",
       "4       21\n",
       "6        8\n",
       "5        5\n",
       "7        4\n",
       "11       2\n",
       "8        2\n",
       "32       1\n",
       "12       1\n",
       "Name: money, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['money'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                 2019-10-212019-10-162019-10-142019-10-142019-1...\n",
       "source               https://www.tribuneindia.com/news/punjab/flood...\n",
       "text                 flood-hit farmers to get 9k-quintal wheat seed...\n",
       "amritsar                                                           223\n",
       "barnala                                                             40\n",
       "bathinda                                                           199\n",
       "faridkot                                                            66\n",
       "fatehgarh sahib                                                    187\n",
       "fazilka                                                            185\n",
       "ferozepur                                                          322\n",
       "gurdaspur                                                          206\n",
       "hoshiarpur                                                          74\n",
       "jalandhar                                                          564\n",
       "kapurthala                                                         227\n",
       "ludhiana                                                           295\n",
       "mansa                                                              115\n",
       "moga                                                               268\n",
       "pathankot                                                           97\n",
       "patiala                                                            358\n",
       "roopnagar                                                           11\n",
       "sangrur                                                            215\n",
       "sas nagar                                                          465\n",
       "sbs nagar                                                           74\n",
       "sri muktsar sahib                                                  350\n",
       "tarn taran                                                          76\n",
       "people                                                            6683\n",
       "crops                                                            13038\n",
       "homes                                                            13664\n",
       "money                                                              664\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyparsing as pp\n",
    "import calendar\n",
    "\n",
    "months_list= []\n",
    "for month_idx in range(1, 13):\n",
    "    months_list.append(calendar.month_name[month_idx])\n",
    "    months_list.append(calendar.month_abbr[month_idx])\n",
    "\n",
    "months_list = [x.lower() for x in months_list]\n",
    "# join the list to use it as pyparsing keyword\n",
    "month_keywords = \" \".join(months_list)\n",
    "\n",
    "# date separator - can be one of '/', '.','-', or ' '\n",
    "separator = pp.Word(\"/.,- \")\n",
    "\n",
    "# Dictionary for numeric date e.g. 12/12/2018\n",
    "numeric_date = pp.Combine(pp.Word(pp.nums, max=2) + separator + pp.Word(pp.nums, max=2) + separator + pp.Word(pp.nums, max=4))\n",
    "\n",
    "# Dictionary for text date e.g. 12/Jan/2018\n",
    "text_date = pp.Combine(pp.Word(pp.nums, max=2) + separator + pp.oneOf(month_keywords) + separator + pp.Word(pp.nums, max=4))\n",
    "#jan 12, 2018\n",
    "text_date2 = pp.Combine(pp.oneOf(month_keywords) + separator + pp.Word(pp.nums, max=2) + separator + pp.Word(pp.nums, max=4))\n",
    "\n",
    "#jan 12\n",
    "text_date3 = pp.Combine(pp.oneOf(month_keywords) + separator + pp.Word(pp.nums, max=2))\n",
    "\n",
    "#12 jan\n",
    "text_date4 = pp.Combine(pp.Word(pp.nums, max=2) + separator + pp.oneOf(month_keywords))\n",
    "\n",
    "# Finding any type of date - except numeric\n",
    "date_patterns = [text_date, text_date2, text_date3, text_date4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Finding the first date in the text - START HERE CAPTURING DATE\n",
    "df_dates = {'index_key': [],\n",
    "            'event_date': []}\n",
    "date_list = []\n",
    "# for j in range(0,len(df)):  \n",
    "for j in range(0,len(df)): \n",
    "    for i, date_pattern in enumerate(date_patterns):\n",
    "        pattern = pp.Suppress(pp.SkipTo(date_pattern)) + date_pattern\n",
    "        try:\n",
    "            result = pattern.parseString(df['text'][j])\n",
    "            df_dates['index_key'].append(j)\n",
    "            df_dates['event_date'].append(result[0])\n",
    "#             print(j, result)\n",
    "        except:\n",
    "            pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event_dates = pd.DataFrame(df_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging event dates with the dataframe\n",
    "df3 = pd.merge(df, event_dates, right_on =  \"index_key\", left_index = True, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df3['event_date'].fillna(\"None Found\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dropping index key row - not needed now that we've merged\n",
    "df3.drop(\"index_key\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting to CSV\n",
    "df3.to_csv(\"./location_topic_counts_events.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
